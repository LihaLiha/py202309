{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "453dace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요.good\n",
      "rank\tIndex\tscore\tsentence\n",
      "1\t473\t0.1111111111111111\tThey said that Tom was a very good actor.\n",
      "2\t175\t0.09090909090909091\tHe thought that the two Cs would look good in advertising.\n",
      "3\t255\t0.08333333333333333\tChildren's minds have more information than before, but is more information good for them?\n",
      "4\t259\t0.08333333333333333\tOne child answered, \"My dream is to go to a very good school.\"\n",
      "5\t539\t0.07142857142857142\tHe talked to the class for half an hour about the importance of good behavior.\n",
      "6\t322\t0.0625\tSome doctors in London say a little humor each day can be good medicine for depression.\n",
      "7\t603\t0.058823529411764705\tIt is also a time to study the Quran and do good deeds such as helping the poor.\n",
      "8\t513\t0.05555555555555555\tAnonymity in cyberworld can certainly be a good thing in some ways, but if it is misused, it can be very offensive.\n",
      "9\t714\t0.05\tIn some ancient European religions, there were 12 good gods and one evil god; the evil god was called the 13th god.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess(sentence): # 주어진 문장을 리스트로 저장\n",
    "    preprocessed_sentence = sentence.strip().split(\" \")\n",
    "    return preprocessed_sentence\n",
    "\n",
    "# 인덱싱 \n",
    "def indexing(file_name): # 주어진 파일에서 각 라인을 읽어와서 전처리된 토큰 리스트로 저장하는 리스트를 생성\n",
    "    file_tokens_pairs = []\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines() # 파일을 읽어서 각 라인을 리스트로 저장\n",
    "    for line in lines:\n",
    "        tokens = preprocess(line)\n",
    "        file_tokens_pairs.append(tokens)\n",
    "    return file_tokens_pairs  # 전처리된 토큰 리스트로 이루어진 리스트를 반환\n",
    "    \n",
    "    # 유사도 측정 함수\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {}\n",
    "    for i in range(len(preprocessed_sentences)):    # 각 문장 유사도를 계산    \n",
    "        # 시작: 대소문자 구분 없는 토큰 셋을 만들기 위한 코드\n",
    "        sentence = preprocessed_sentences[i]\n",
    "        query_str = ' '.join(preprocessed_query).lower()\n",
    "        sentence_str = ' '.join(sentence).lower()\n",
    "        preprocessed_query = set(preprocess(query_str))\n",
    "        preprocessed_sentence = preprocess(sentence_str)            \n",
    "        # 끝: 대소문자 구분 없는 토큰 셋을 만들기 위한 코드               \n",
    "        \n",
    "        file_token_set = set(preprocessed_sentence)\n",
    "        all_tokens = preprocessed_query | file_token_set\n",
    "        same_tokens = preprocessed_query & file_token_set\n",
    "        # 유사도를 계산하고 딕셔너리에 저장\n",
    "        similarity = len(same_tokens) / len(all_tokens)\n",
    "        score_dict[i] = similarity\n",
    "        \n",
    "    return score_dict  # 딕셔너리 반환\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# 1. 인덱싱\n",
    "## https://github.com/jungyeul/korean-parallel-corpora\n",
    "\n",
    "file_name = \"jhe-koen-dev.en\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "\n",
    "\n",
    "# 2. 쿼리 입력하기\n",
    "query = input(\"영어 쿼리를 입력하세요.\")\n",
    "preprocessed_query = preprocess(query) # 입력받은 쿼리 전처리\n",
    "query_token_set = set(preprocessed_query)\n",
    "\n",
    "# 3. Calculate similarities based on a same token set\n",
    "score_dict = calc_similarity(query_token_set, file_tokens_pairs)\n",
    "\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "# score_dict의 항목들을 값을 기준으로 내림차순으로 정렬하여 리스트로 반환\n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. 결과 출력\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\")\n",
    "    rank = 1\n",
    "    \n",
    "    # 최대 10위까지 출력\n",
    "    for i, score  in sorted_score_list:      \n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10:\n",
    "            break\n",
    "            \n",
    "        # 0점인 결과 출력 X\n",
    "        if sorted_score_list[rank][1] == 0.0:\n",
    "            break\n",
    "            \n",
    "        rank = rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6e070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
